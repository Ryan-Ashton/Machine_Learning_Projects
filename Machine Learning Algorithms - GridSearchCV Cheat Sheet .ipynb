{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': True}\n",
      "-------------------------\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
      "-------------------------\n",
      "{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
      "-------------------------\n",
      "{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3,4,5,6,7]).reshape(-1, 1)\n",
    "y = np.array([2,4,6,8,10,12,14])\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "\n",
    "params = {'fit_intercept': (True, False), 'normalize': (True, False), 'copy_X':(True, False), 'n_jobs':[1,2,3,4,5]}\n",
    "\n",
    "\n",
    "search = GridSearchCV(regressor, params).fit(X,y)\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "regressor = SVR(kernel='rbf', degree=3, gamma='auto', coef0=0.0, tol=0.001,\n",
    "                C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "params = {'kernel':['rbf'], 'degree':[3], 'gamma':['auto'], 'coef0':[0.0], 'tol':[0.001],\n",
    "                'C':[1.0], 'epsilon':[0.1], 'shrinking':(True, False), 'cache_size':[200], 'verbose':(True, False), 'max_iter':[-1]}\n",
    "\n",
    "search = GridSearchCV(regressor, params).fit(X,y)\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "###########\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                  min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                  random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                  min_impurity_split=None, presort=False)\n",
    "\n",
    "params = {'criterion':['mse'], 'splitter':['best'], 'max_depth':[None], 'min_samples_split':[2],\n",
    "                                  'min_samples_leaf':[1], 'min_weight_fraction_leaf':[0.0], 'max_features':[None],\n",
    "                                  'random_state':[None], 'max_leaf_nodes':[None], 'min_impurity_decrease':[0.0],\n",
    "                                  'min_impurity_split':[None], 'presort':(True, False)}\n",
    "\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "###########\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                                  min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None,\n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True,\n",
    "                                  oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "params = {'n_estimators':[10], 'criterion':['mse'], 'max_depth':[None], 'min_samples_split':[2], 'min_samples_leaf':[1],\n",
    "                                  'min_weight_fraction_leaf':[0.0], 'max_features':['auto'], 'max_leaf_nodes':[None],\n",
    "                                  'min_impurity_decrease':[0.0], 'min_impurity_split':[None], 'bootstrap':(True, False),\n",
    "                                  'oob_score':(True, False), 'n_jobs':[1], 'random_state':[None], 'verbose':[0], 'warm_start':(True, False)}\n",
    "\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': True}\n",
      "-------------------------\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]{'C': 1.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
      "-------------------------\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': True, 'random_state': None, 'verbose': 0, 'warm_start': True}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3,4,5,6,7]).reshape(-1, 1)\n",
    "y = np.array([1,0,0,1,0,1,1])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,\n",
    "                                fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "                                random_state=None, solver='liblinear', max_iter=100, multi_class='ovr',\n",
    "                                verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "params = {'penalty':['l2'], 'dual':(True, False), 'tol':[0.0001], 'C':[1.0],\n",
    "                                'fit_intercept':(True, False), 'intercept_scaling':[1], 'class_weight':[None],\n",
    "                                'random_state':[None], 'solver':['liblinear'], 'max_iter':[100], 'multi_class':['ovr'],\n",
    "                                'verbose':[0], 'warm_start':(True,False), 'n_jobs':[1]}\n",
    "\n",
    "\n",
    "search = GridSearchCV(classifier, params).fit(X,y)\n",
    "\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "###########\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto',\n",
    "#                                   leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "\n",
    "# params = {'n_neighbors':[5], 'weights':['uniform'], 'algorithm':['auto'], 'leaf_size':[30], 'p':[2],\n",
    "#                                   'metric':['minkowski'], 'metric_params':[None], 'n_jobs':[1]}\n",
    "\n",
    "\n",
    "# search = GridSearchCV(classifier, params).fit(X,y)\n",
    "\n",
    "# print(classifier.best_params_)\n",
    "# print(\"-------------------------\")\n",
    "\n",
    "############\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True,\n",
    "                 probability=False, tol=0.001, cache_size=200, class_weight=None,\n",
    "                 verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "\n",
    "\n",
    "params = {'C':[1.0], 'kernel':['rbf'], 'degree':[3], 'gamma':['auto'], 'coef0':[0.0], 'shrinking':(True,False),\n",
    "                 'probability':(True, False), 'tol':[0.001], 'cache_size':[200], 'class_weight':[None],\n",
    "                 'verbose':(True, False), 'max_iter':[-1], 'decision_function_shape':['ovr'], 'random_state':[None]}\n",
    "\n",
    "search = GridSearchCV(classifier, params).fit(X,y)\n",
    "\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "############\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB #NLP as well\n",
    "\n",
    "classifier = GaussianNB(priors=None)\n",
    "\n",
    "############\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "classifier = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                                    min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                    bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0,\n",
    "                                    warm_start=False, class_weight=None)\n",
    "\n",
    "params = {'n_estimators':[10], 'criterion':['gini'], 'max_depth':[None], 'min_samples_split':[2],\n",
    "                                    'min_samples_leaf':[1], 'min_weight_fraction_leaf':[0.0], 'max_features':['auto'],\n",
    "                                    'max_leaf_nodes':[None], 'min_impurity_decrease':[0.0], 'min_impurity_split':[None],\n",
    "                                    'bootstrap':[True], 'oob_score':(True, False), 'n_jobs':[1], 'random_state':[None], 'verbose':[0],\n",
    "                                    'warm_start':(True, False), 'class_weight':[None]}\n",
    "\n",
    "\n",
    "search = GridSearchCV(classifier, params).fit(X,y)\n",
    "\n",
    "\n",
    "print(search.best_params_)\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
